{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce0bf7eb-43c8-4745-b9f6-6126757ab11c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets, transforms\n",
    "from tqdm.auto import tqdm\n",
    "import os\n",
    "from PIL import Image\n",
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "043e24b3-2050-4bf2-bbbd-e28585d80a2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_valid_image(filepath):\n",
    "    try:\n",
    "        with Image.open(filepath) as img:\n",
    "            img.verify()\n",
    "        return True\n",
    "    except:\n",
    "        print(f\"Corrupted image found: {filepath}\", file=sys.stderr)\n",
    "        return False\n",
    "\n",
    "class FilteredImageFolder(datasets.ImageFolder):\n",
    "    def __init__(self, root, transform=None):\n",
    "        super(FilteredImageFolder, self).__init__(root=root, transform=transform)\n",
    "        # Filter out corrupt images\n",
    "        valid_images = []\n",
    "        for item in self.imgs:\n",
    "            if is_valid_image(item[0]):\n",
    "                valid_images.append(item)\n",
    "        self.imgs = valid_images\n",
    "        self.samples = valid_images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2608f123-1c84-4c73-9dbc-dd52d3390609",
   "metadata": {},
   "outputs": [],
   "source": [
    "img_width, img_height = 150, 150\n",
    "batch_size = 32\n",
    "num_epochs = 10\n",
    "\n",
    "# Data augmentation and normalization for training\n",
    "# Just normalization for validation\n",
    "train_transform = transforms.Compose([\n",
    "    transforms.Resize((img_width, img_height)),\n",
    "    transforms.RandomRotation(40),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.RandomAffine(0, translate=(0.2, 0.2), scale=(0.8, 1.2), shear=0.2),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "val_transform = transforms.Compose([\n",
    "    transforms.Resize((img_width, img_height)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44c36d11-8f0a-4142-83b0-5da002c74e16",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Loading and validating training dataset...\")\n",
    "train_dataset = FilteredImageFolder(\n",
    "    root='dataset/train',\n",
    "    transform=train_transform\n",
    ")\n",
    "\n",
    "print(\"Loading and validating validation dataset...\")\n",
    "val_dataset = FilteredImageFolder(\n",
    "    root='dataset/validation',\n",
    "    transform=val_transform\n",
    ")\n",
    "\n",
    "print(\"Training classes:\", train_dataset.classes)\n",
    "print(\"Validation classes:\", val_dataset.classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15ef03d9-b3fe-4e2e-950d-4c56d2bb8610",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DataLoader(\n",
    "    train_dataset,\n",
    "    batch_size=batch_size,\n",
    "    shuffle=True,\n",
    "    num_workers=0,\n",
    "    pin_memory=True\n",
    ")\n",
    "\n",
    "val_loader = DataLoader(\n",
    "    val_dataset,\n",
    "    batch_size=batch_size,\n",
    "    shuffle=False,\n",
    "    num_workers=0,\n",
    "    pin_memory=True\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6e8c490-1d50-4a2a-aab7-314483921951",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNNClassifier(nn.Module):\n",
    "    def __init__(self, num_classes):\n",
    "        super(CNNClassifier, self).__init__()\n",
    "        self.features = nn.Sequential(\n",
    "            # First convolutional block\n",
    "            nn.Conv2d(3, 32, 3),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2, 2),\n",
    "            \n",
    "            # Second convolutional block\n",
    "            nn.Conv2d(32, 64, 3),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2, 2),\n",
    "            \n",
    "            # Third convolutional block\n",
    "            nn.Conv2d(64, 128, 3),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2, 2),\n",
    "            \n",
    "            # Fourth convolutional block\n",
    "            nn.Conv2d(128, 128, 3),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2, 2)\n",
    "        )\n",
    "        \n",
    "        self.avg_pool = nn.AdaptiveAvgPool2d((1, 1))\n",
    "        \n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(128, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(512, num_classes)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.features(x)\n",
    "        x = self.avg_pool(x)\n",
    "        x = self.classifier(x)\n",
    "        return x\n",
    "\n",
    "# Initialize model, loss function, and optimizer\n",
    "model = CNNClassifier(num_classes=len(train_dataset.classes))\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters())\n",
    "\n",
    "# Print model summary\n",
    "def count_parameters(model):\n",
    "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "print(f\"\\nModel Parameters: {count_parameters(model):,}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a1054e8-06fc-482f-a5f1-a032fd9280fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Lists to store losses\n",
    "train_losses = []\n",
    "val_losses = []\n",
    "\n",
    "# Modified training loop to track losses\n",
    "best_val_acc = 0.0\n",
    "for epoch in range(num_epochs):\n",
    "    print(f'\\nEpoch [{epoch+1}/{num_epochs}]')\n",
    "    \n",
    "    # Training phase\n",
    "    model.train()\n",
    "    train_loss = 0.0\n",
    "    train_correct = 0\n",
    "    train_total = 0\n",
    "    \n",
    "    pbar = tqdm(total=len(train_loader), desc=f'Training')\n",
    "    for i, (inputs, labels) in enumerate(train_loader):\n",
    "        inputs, labels = inputs, labels\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        \n",
    "        grad_norms = {}\n",
    "        for name, param in model.named_parameters():\n",
    "            if param.grad is not None:\n",
    "                grad_norms[name] = param.grad.norm().item()\n",
    "        \n",
    "        optimizer.step()\n",
    "        \n",
    "        train_loss += loss.item()\n",
    "        _, predicted = outputs.max(1)\n",
    "        train_total += labels.size(0)\n",
    "        train_correct += predicted.eq(labels).sum().item()\n",
    "        \n",
    "        avg_loss = train_loss / (i + 1)\n",
    "        acc = 100. * train_correct / train_total\n",
    "        pbar.set_description(f'Train | Loss: {avg_loss:.4f} | Acc: {acc:.2f}%')\n",
    "        pbar.update(1)\n",
    "    \n",
    "    pbar.close()\n",
    "    \n",
    "    # Store average training loss\n",
    "    train_losses.append(train_loss / len(train_loader))\n",
    "    \n",
    "    print(\"\\nGradient Norms:\")\n",
    "    for name, norm in grad_norms.items():\n",
    "        print(f\"{name}: {norm:.4f}\")\n",
    "    \n",
    "    # Validation phase\n",
    "    model.eval()\n",
    "    val_loss = 0.0\n",
    "    val_correct = 0\n",
    "    val_total = 0\n",
    "    \n",
    "    pbar = tqdm(total=len(val_loader), desc=f'Validation')\n",
    "    with torch.no_grad():\n",
    "        for i, (inputs, labels) in enumerate(val_loader):\n",
    "            inputs, labels = inputs, labels\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            \n",
    "            val_loss += loss.item()\n",
    "            _, predicted = outputs.max(1)\n",
    "            val_total += labels.size(0)\n",
    "            val_correct += predicted.eq(labels).sum().item()\n",
    "            \n",
    "            avg_loss = val_loss / (i + 1)\n",
    "            acc = 100. * val_correct / val_total\n",
    "            pbar.set_description(f'Val | Loss: {avg_loss:.4f} | Acc: {acc:.2f}%')\n",
    "            pbar.update(1)\n",
    "    \n",
    "    pbar.close()\n",
    "    \n",
    "    # Store average validation loss\n",
    "    val_losses.append(val_loss / len(val_loader))\n",
    "    \n",
    "    train_acc = 100. * train_correct / train_total\n",
    "    val_acc = 100. * val_correct / val_total\n",
    "    \n",
    "    print(f'\\nEpoch Summary:')\n",
    "    print(f'Train Loss: {train_loss/len(train_loader):.4f}, Train Acc: {train_acc:.2f}%')\n",
    "    print(f'Val Loss: {val_loss/len(val_loader):.4f}, Val Acc: {val_acc:.2f}%')\n",
    "    \n",
    "    if val_acc > best_val_acc:\n",
    "        best_val_acc = val_acc\n",
    "        torch.save(model.state_dict(), 'catsanddogs_classifier.pth')\n",
    "        print(f'New best model saved! (Validation Accuracy: {val_acc:.2f}%)')\n",
    "\n",
    "# Plotting code\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.plot(range(1, num_epochs+1), train_losses, label='Training Loss', marker='o')\n",
    "plt.plot(range(1, num_epochs+1), val_losses, label='Validation Loss', marker='o')\n",
    "plt.title('Training and Validation Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.savefig('loss_plot_cnn.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "026f624f-a5b2-4e43-8afd-a797577f39db",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model, 'catsanddogs_classifier_full.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e814e9d5-8c20-4a07-b6cf-ab3d9c075cba",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8, 6))\n",
    "plt.plot(range(1, num_epochs+1), train_losses, label='Training Loss', marker='o')\n",
    "plt.plot(range(1, num_epochs+1), val_losses, label='Validation Loss', marker='o')\n",
    "plt.title('Training and Validation Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.savefig('loss_plot_cnn.png')\n",
    "plt.show()  # Optional: Display the plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad0c3819-4950-44c5-b56f-c385ed10edc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_image(image_path, model, transform, device, classes=['cats', 'dogs']):\n",
    "    from PIL import Image\n",
    "    import torch\n",
    "    try:\n",
    "        # Set model to evaluation mode\n",
    "        model.eval()\n",
    "        # Open and preprocess the image\n",
    "        image = Image.open(image_path).convert('RGB')  # Ensure RGB format\n",
    "        image = transform(image).unsqueeze(0)  # Apply transform and add batch dimension\n",
    "        image = image.to(device)  # Move to the same device as the model\n",
    "        \n",
    "        # Perform inference\n",
    "        with torch.no_grad():\n",
    "            output = model(image)\n",
    "            probabilities = torch.softmax(output, dim=1)  # Apply softmax to get probabilities\n",
    "            predicted_idx = torch.argmax(probabilities, dim=1).item()  # Get predicted class index\n",
    "            predicted_label = classes[predicted_idx]  # Map index to class name\n",
    "            predicted_prob = probabilities[0, predicted_idx].item()  # Get probability of predicted class\n",
    "        \n",
    "        return predicted_label, predicted_prob\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing image {image_path}: {str(e)}\")\n",
    "        return None, None\n",
    "\n",
    "# Example inference\n",
    "sample_image_path = 'cats.png'  # Replace with your image path\n",
    "label, prob = predict_image(sample_image_path, model, val_transform, device, train_dataset.classes)\n",
    "if label is not None:\n",
    "    print(f\"Predicted: {label}, Probability: {prob:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a988b168-dcb6-42f5-a078-19c9cf1d5c93",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
